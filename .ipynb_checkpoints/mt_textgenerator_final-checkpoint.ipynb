{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell handles imports / set ups\n",
    "\n",
    "##LIBRARIES\n",
    "\n",
    "#\"Faker is a Python package that generates fake data for you. \" [from the Faker documentation]\n",
    "#import faker library\n",
    "from faker import Faker\n",
    "#create an instance of Faker\n",
    "fake = Faker()\n",
    "\n",
    "import copy as cp #to copy variables (assignments in python are object references)\n",
    "\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Set the precision of decimals for the whole notebook on 2\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL CONTAINS SOME SIMPLE FUNCTIONS WHICH WILL BE USED MORE OFTEN IN THE PROGRAMM\n",
    "\n",
    "#Declare a decision boundry function, to create a boundry value each time a decision is to be made**\n",
    "def decide():\n",
    "    decision_boundry = np.random.uniform(0,1,1)\n",
    "    return decision_boundry\n",
    "\n",
    "#Declare a function to let values vary along a uniform distribution around a given variation. This is a placeholder function for **\n",
    "def uniform_variance(value, variation):\n",
    "    low_boarder = float(value) - float(value) * float(variation)\n",
    "    top_boarder = float(value) + float(value) * float(variation)\n",
    "    \n",
    "    value = cp.deepcopy(np.random.uniform(low_boarder,top_boarder,1))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "###GENERATE BAG OF UNIQUE ELEMENTS\n",
    "##Also gnerate a bag for frequently used words for sentence generation in the abstracts\n",
    "##Set the size of the bag of unique Elements\n",
    "\n",
    "words_to_create = 150000\n",
    "\n",
    "\n",
    "#This function takes an integer and returns a list of unique words which is the size of the given integer minus deletet doublicates \n",
    "def create_bag_of_unique_words(word_amount_to_create):\n",
    "\n",
    "    words = []\n",
    "\n",
    "    words_created=0\n",
    "    \n",
    "    while words_created < word_amount_to_create:\n",
    "        words.append(fake.word())\n",
    "        words_created = words_created + 1 \n",
    "\n",
    "    \n",
    "    #check for duplikates\n",
    "    unique_words = []\n",
    "    double = 0\n",
    "    for x in words:\n",
    "        if x not in unique_words:\n",
    "            unique_words.append(x)\n",
    "        else:\n",
    "            double=+1\n",
    "    print(double)\n",
    "    return unique_words\n",
    "            \n",
    "            \n",
    "#CREATE A FUNCTION FOR FREQUENTLY USED WORDS (FOR SENTENCE GENERATION)\n",
    "def create_bag_of_frequently_used_words(bagsize):\n",
    "    #Create a list of frequently used words\n",
    "    frequently_used_words=[]\n",
    "    frequently_used_words.append(unique_words[:bagsize])\n",
    "    del unique_words[:bagsize]\n",
    "    \n",
    "    return frequently_used_words\n",
    "\n",
    "unique_words = create_bag_of_unique_words(words_to_create)\n",
    "frequently_used_words = create_bag_of_frequently_used_words(20)\n",
    "\n",
    "## Comment:\n",
    "#Combination of frequently used words and 'normal' words to create sentences with topic words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], []]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###INITIALIZE EMPTY TOPICS\n",
    "\n",
    "##Create bag of x topics\n",
    "topic_amount = 5\n",
    "\n",
    "#This function takes an amount of topics as integer and returns a list of empty lists according to the amount\n",
    "def initialize_empty_topics(amounts_of_topics):\n",
    "    \n",
    "    topics_to_create = amounts_of_topics\n",
    "\n",
    "    ##Create empty list of initial topics\n",
    "    topic_list_empty = []\n",
    "    topics_created = 0\n",
    "    while topics_created < topics_to_create:\n",
    "        topic_list_empty.insert(0, [])\n",
    "        topics_created += 1\n",
    "    \n",
    "    return topic_list_empty\n",
    "\n",
    "\n",
    "topic_list_empty = initialize_empty_topics(topic_amount)\n",
    "\n",
    "topic_list_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###INITIALIZE KEYWORDS FOR EACH TOPIC\n",
    "\n",
    "#State the low and top boarder for key words per topic\n",
    "min_words_per_topic = 2\n",
    "max_words_per_topic = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define a function which will insert the initial keywords for every topic\n",
    "def initialize_keywords_to_topic(empty_topic_list):\n",
    "    for topic in empty_topic_list:\n",
    "        keyword_amount = rnd.randint(min_words_per_topic, max_words_per_topic)\n",
    "        keywords_inserted = 0\n",
    "        while keywords_inserted < keyword_amount:\n",
    "            #Append a unique word to the topic as a keyword of this topic\n",
    "            topic.insert(0,unique_words[keywords_inserted])\n",
    "            #Delete the word out of the baggs of words to ensure, this entry won't be taken a second time\n",
    "            del unique_words[keywords_inserted]\n",
    "            keywords_inserted = keywords_inserted +1\n",
    "    return (empty_topic_list)\n",
    "\n",
    "topic_list = initialize_keywords_to_topic(topic_list_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['card', 'until'],\n",
       " ['far', 'report', 'former'],\n",
       " ['again', 'long'],\n",
       " ['everybody', 'before', 'while'],\n",
       " ['treatment', 'strong']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###INITIALIZE BEHAVIOURAL PROBABILITIES FOR EACH TOPIC\n",
    "\n",
    "##This function takes an empty topic list and generate for each topic probabilities\n",
    "##Note: The behaviours are implemented as fucntions which are called depending on a random decisionboundry for each \n",
    "##generation step and in this function (initialize_topic_behaviour_parameters) stated probabilities. This \n",
    "##implementation aims to mimic tendencies for behaviours.\n",
    "def initialize_topic_behaviour_parameters(empty_topic_list):\n",
    "\n",
    "    for topic in empty_topic_list:\n",
    "        \n",
    "        \n",
    "        #Initialize the behavioural parameters**\n",
    "        topic_probability_is_elaborated = [float(np.random.uniform(0,1,1)), [0], []]\n",
    "        \n",
    "        topic_probability_creates_new_word = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        topic_probability_uses_different_topic = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        #topic_probability_is_used = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        \n",
    "        #Setting the behavioural parameters here just with implemented with standard uniform distributions in a certain range\n",
    "        #between 0 and 1. Refining these functions in future work could include changing behavioural probabilities depending \n",
    "        #on topic size and topic contents.\n",
    "        \n",
    "        \n",
    "        behavioural_paramters = [topic_probability_is_elaborated, topic_probability_creates_new_word,\n",
    "                                 topic_probability_uses_different_topic] #topic_probability_is_used,]\n",
    "        #,topic_probability_creates_new_word, topic_probability_uses_different_topic\n",
    "        \n",
    "\n",
    "        ##FUTURE WORK: Disruptive Technologien implementieren: Ein Topic einstampfen, wenn ein anderes Steigt.\n",
    "        ##FUTRE WORK: Ressourcen pro Generation implementieren, so wie es wörter für topic gibt, kann es\n",
    "        ##Topics für neue Generation geben. --> Es wird festgelegt wie viele Topics pro Generation generiert werden\n",
    "        ##können / sollen und dann wird die Anzahl gemäß den Wahrscheinlichkeiten als Anteil zugewiesen.\n",
    "\n",
    "        topic.append(behavioural_paramters)\n",
    "        \n",
    "\n",
    "        #IMPORTNANT NOTE:\n",
    "        #BEHAVIOUR 1 = IF TOPIC IS ELABORATED\n",
    "        #BEHAVIOUR 2 = TOPIC CREATES NEW WORD\n",
    "        #BEHAVIOUR 3 = TOPIC USES DIFFERENT TOPIC\n",
    "        #BEHAVIOUR 4 = TOPIC IS USED IN DIFFERENT TOPIC\n",
    "\n",
    "initialize_topic_behaviour_parameters(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['card',\n",
       "  'until',\n",
       "  [[0.4307962042934016, [0], []],\n",
       "   [0.13339341808114996, [0], []],\n",
       "   [0.15652626593693458, [0], []]]],\n",
       " ['far',\n",
       "  'report',\n",
       "  'former',\n",
       "  [[0.11112862719421723, [0], []],\n",
       "   [0.10417855426380251, [0], []],\n",
       "   [0.2439694840559346, [0], []]]],\n",
       " ['again',\n",
       "  'long',\n",
       "  [[0.6387712318027251, [0], []],\n",
       "   [0.1557547229859268, [0], []],\n",
       "   [0.3320212667892403, [0], []]]],\n",
       " ['everybody',\n",
       "  'before',\n",
       "  'while',\n",
       "  [[0.2509518650305682, [0], []],\n",
       "   [0.3849988216740005, [0], []],\n",
       "   [0.4842388641468727, [0], []]]],\n",
       " ['treatment',\n",
       "  'strong',\n",
       "  [[0.8988003340161814, [0], []],\n",
       "   [0.38094805611950366, [0], []],\n",
       "   [0.09059184786225716, [0], []]]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENSFUNKTIONEN\n",
    "\n",
    "#merge_topic_with_unique_word takes a word (from a topic) and merges it with a random word from unique_words.\n",
    "def merge_topicword_with_uniqueword(word):\n",
    "    word_position = rnd.randint(0,len(unique_words)-1)\n",
    "    new_word = str(word) + str(unique_words[word_position])\n",
    "    \n",
    "    #if the word becomes to long keep the last 12 digits\n",
    "    if len(new_word)>18:\n",
    "        new_word = new_word[-12:]\n",
    "    return new_word\n",
    "\n",
    "def use_different_topic(topic_list):\n",
    "    # This implementation enables the error of elaborating on the own topic when choosing a random other topic.\n",
    "    \n",
    "    random_topic_number = rnd.randint(0,len(topic_list)-1)\n",
    "    if random_topic_number < 0:\n",
    "        random_topic_number = 0\n",
    "    \n",
    "    word_position_in_topic = rnd.randint(0,len(topic_list[random_topic_number])-2)\n",
    "    if word_position_in_topic < 0:\n",
    "        word_position_in_topic = 0\n",
    "    \n",
    "    new_word = topic_list[random_topic_number][word_position_in_topic]\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ZÄHLFUNKTIONEN\n",
    "\n",
    "#This function will iterate over the new topic generation and check the behavioural appereance list to set counter\n",
    "def simple_count_function_1(topic_list):\n",
    "    if boolean == True:\n",
    "        print(\"wait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENVERÄNDERUNGSFUNKTIONEN\n",
    "\n",
    "def simple_behaviour_change(topic):\n",
    "    \n",
    "    temporary_topic = cp.deepcopy(topic)\n",
    "    \n",
    "    for behaviour in temporary_topic[-1]:\n",
    "        \n",
    "        behaviour[0] = uniform_variance(behaviour[0],0.4)\n",
    "\n",
    "        if behaviour[0] > 1:\n",
    "            behaviour[0] = 0.98\n",
    "    \n",
    "    return temporary_topic\n",
    "\n",
    "#A more complex version could be embedded with:\n",
    "#def simple_behaviour_change(topic):\n",
    "#    while True:\n",
    "#        topic[index of one behaviour]: do something\n",
    "#        topic[index of one behaviour]: do something\n",
    "#        ...        \n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE SUBTOPIC SPACE\n",
    "\n",
    "#this function takes a topic and elaborates a subtopic space on one topic, including changing behavioural probabilities and\n",
    "#counting if behaviours were triggered.\n",
    "\n",
    "\n",
    "#PROBLEMATIK BEI DER IMPLEMENTIERUNG HIER, DASS EIN TOPIC MEHRMALS AUSGEARBEITET WIRD SO\n",
    "#Elaborate the behaviour to the next generation and store initial 0s into the behaviour appereance lists of booleans\n",
    "#(these 0s can then be replaced with 1s if a behaviour is triggered)\n",
    "\n",
    "\n",
    "def elaborate_topic(topic):\n",
    "    \n",
    "    subtopic_space = cp.deepcopy(topic[-1:])\n",
    "    #This slice appends the previous behaviour parameters to the subtopic space (the : is to keep the same list structure, as \n",
    "    #if the topic words would have also been taken)\n",
    "\n",
    "\n",
    "    subtopic_space = simple_behaviour_change(subtopic_space)\n",
    "\n",
    "    \n",
    "    #Set the amounts of words used in that subtopic**\n",
    "    subtopic_word_amount = rnd.randint(4,6)\n",
    "    subtopic_words_picked = 0\n",
    "    \n",
    "\n",
    "    while subtopic_words_picked < subtopic_word_amount:\n",
    "        \n",
    "        decisionboundry = decide()\n",
    "        \n",
    "        #Maybe create a new word\n",
    "        if subtopic_space[-1][1][0] > decisionboundry + 0.2: #(REF2)\n",
    "            \n",
    "            new_word = cp.deepcopy(merge_topicword_with_uniqueword(topic[rnd.randint(0,len(topic)-2)]))\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            subtopic_words_picked += 1\n",
    "\n",
    "            subtopic_space[-1][1][-1].pop(0)\n",
    "            subtopic_space[-1][1][-1].insert(0,1) #(REF3)\n",
    "            \n",
    "        #Maybe use a different topic\n",
    "        if subtopic_space[-1][2][0] > decisionboundry: #(REF 4)\n",
    "            t_random_1 = rnd.randint(0,len(topic_list)-1)\n",
    "            new_word = cp.deepcopy(use_different_topic(topic_list))\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            subtopic_words_picked += 1            \n",
    "\n",
    "            subtopic_space[-1][2][-1].pop(0)\n",
    "            subtopic_space[-1][2][-1].insert(0,1) #(REF3)\n",
    "        \n",
    "        \n",
    "        #Fill rest of subtopic with topic words\n",
    "        while subtopic_words_picked < subtopic_word_amount:\n",
    "            position_word_elaborated = rnd.randint(0,len(topic)-2) #(REF1)\n",
    "            subtopic_space.insert(0,topic[position_word_elaborated])\n",
    "            subtopic_words_picked += 1     \n",
    "        \n",
    "    return subtopic_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL WILL ELABORATE A TOPIC_SPACE INTO A NEW GENERATION BY USING THE elaborate_topic FUNCTION.\n",
    "\n",
    "master = []\n",
    "temp_gen = []\n",
    "\n",
    "def elaborate_topic_space(topic_generation):\n",
    "    \n",
    "        \n",
    "    temporary_generation = cp.deepcopy(topic_generation)\n",
    "\n",
    "\n",
    "    #For createing a new generation, give 0s as in the behaviour appearence list for every behaviour on every topic for this generation\n",
    "    for topic in temporary_generation:\n",
    "        for behaviour in topic[-1]:\n",
    "            behaviour[-1].insert(0,0)\n",
    "\n",
    "    for topic in temporary_generation:\n",
    "\n",
    "        new_subtopic_space = []\n",
    "        \n",
    "        topic_counter = 0\n",
    "        max_amount_subtopics = 10\n",
    "        \n",
    "        #This loop elaborates a topic dpeending on its probability to be elaborated until the decision_boundry will be\n",
    "        #above the topic probability for being elaborated\n",
    "        while topic_counter < max_amount_subtopics: \n",
    "\n",
    "            \n",
    "            decision_boundry = decide()\n",
    "        \n",
    "            if topic[-1][0][0]> decision_boundry:\n",
    "      \n",
    "\n",
    "                #Call the elaborate_topic_function which returns a subtopic space for the topic including new elements and \n",
    "                temp_gen.insert(0,elaborate_topic(topic)) #elaborate topic uses cp.deepcopy(topic) to generate a clone not a clone of the object pointer\n",
    "                \n",
    "                topic_counter += 1\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    \n",
    "    new_generation = [element for element in temp_gen if element != []]\n",
    "\n",
    "    master.insert(0,cp.deepcopy(new_generation))     \n",
    "    \n",
    "    return(new_generation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(REF 1) #This sets a list of 0s for each generation for every topic behaviour as preset, which\n",
    "    #can then be set to one if it is triggered. This is important to embedd here (before elaborating a single topic), so the logic\n",
    "    #of adressing appeareances of behaviours can be implemented with one logic, alway setting the first entry in the behaviour\n",
    "    #appearence list to one, which is with this implementation by default at 0 for each generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = []\n",
    "\n",
    "def start_generator(initial_topic_list):\n",
    "    \n",
    "    \n",
    "    #Initialize the new_topic_generation which is handed to the elaborate_topic_list function\n",
    "    next_topic_generation = elaborate_topic_space(initial_topic_list)\n",
    "    \n",
    "    master.insert(0,next_topic_generation)\n",
    "\n",
    "    #State the amount of generations\n",
    "    amount_of_generations = 4\n",
    "    generations_created = 0\n",
    "    \n",
    "    while generations_created < amount_of_generations:\n",
    "\n",
    "        next_topic_generation = elaborate_topic_space(next_topic_generation)\n",
    "        print(generations_created)\n",
    "        print(\"generations_created\")\n",
    "        master.insert(0,next_topic_generation)\n",
    "        print(generations_created)\n",
    "        print(\"generadadddddddddddddddddtions_created\")\n",
    "\n",
    "        generations_created = generations_created + 1\n",
    "\n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "generations_created\n",
      "0\n",
      "generadadddddddddddddddddtions_created\n",
      "1\n",
      "generations_created\n",
      "1\n",
      "generadadddddddddddddddddtions_created\n",
      "2\n",
      "generations_created\n",
      "2\n",
      "generadadddddddddddddddddtions_created\n"
     ]
    }
   ],
   "source": [
    "start_generator(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
