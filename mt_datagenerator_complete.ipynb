{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import faker library\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "import copy as cp\n",
    "\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Set the precision of decimals for the whole notebook on 2\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS CELL CONTAINS SOME SIMPLE FUNCTIONS WHICH WILL BE USED MORE OFTEN IN THE PROGRAMM\n",
    "\n",
    "#Declare a decision boundry function, to create a boundry value each time a decision is to be made**\n",
    "def decide():\n",
    "    decision_boundry = np.random.uniform(0,1,1)\n",
    "    return decision_boundry\n",
    "\n",
    "#Declare a function to let values vary along a uniform distribution around a given variation. This is a placeholder function for **\n",
    "def uniform_variance(value, variation):\n",
    "    low_boarder = float(value) - float(value) * float(variation)\n",
    "    top_boarder = float(value) + float(value) * float(variation)\n",
    "    \n",
    "    value = cp.deepcopy(np.random.uniform(low_boarder,top_boarder,1))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "###GENERATE BAG OF UNIQUE ELEMENTS\n",
    "##Also gnerate a bag for frequently used words for sentence generation in the abstracts\n",
    "##Set the size of the bag of unique Elements\n",
    "\n",
    "words_to_create = 150000\n",
    "\n",
    "\n",
    "#This function takes an integer and returns a list of unique words which is the size of the given integer minus deletet doublicates \n",
    "def create_bag_of_unique_words(word_amount_to_create):\n",
    "\n",
    "    words = []\n",
    "\n",
    "    words_created=0\n",
    "    \n",
    "    while words_created < word_amount_to_create:\n",
    "        words.append(fake.word())\n",
    "        words_created = words_created + 1 \n",
    "\n",
    "    \n",
    "    #check for duplikates\n",
    "    unique_words = []\n",
    "    double = 0\n",
    "    for x in words:\n",
    "        if x not in unique_words:\n",
    "            unique_words.append(x)\n",
    "        else:\n",
    "            double=+1\n",
    "    print(double)\n",
    "    return unique_words\n",
    "            \n",
    "            \n",
    "#CREATE A FUNCTION FOR FREQUENTLY USED WORDS (FOR SENTENCE GENERATION)\n",
    "def create_bag_of_frequently_used_words(bagsize):\n",
    "    #Create a list of frequently used words\n",
    "    frequently_used_words=[]\n",
    "    frequently_used_words.append(unique_words[:bagsize])\n",
    "    del unique_words[:bagsize]\n",
    "    \n",
    "    return frequently_used_words\n",
    "\n",
    "unique_words = create_bag_of_unique_words(words_to_create)\n",
    "frequently_used_words = create_bag_of_frequently_used_words(20)\n",
    "\n",
    "## Comment:\n",
    "#Combination of frequently used words and 'normal' words to create sentences with topic words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], []]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###INITIALIZE EMPTY TOPICS\n",
    "\n",
    "##Create bag of x topics\n",
    "topic_amount = 5\n",
    "\n",
    "#This function takes an amount of topics as integer and returns a list of empty lists according to the amount\n",
    "def initialize_empty_topics(amounts_of_topics):\n",
    "    \n",
    "    topics_to_create = amounts_of_topics\n",
    "\n",
    "    ##Create empty list of initial topics\n",
    "    topic_list_empty = []\n",
    "    topics_created = 0\n",
    "    while topics_created < topics_to_create:\n",
    "        topic_list_empty.insert(0, [])\n",
    "        topics_created += 1\n",
    "    \n",
    "    return topic_list_empty\n",
    "\n",
    "\n",
    "topic_list_empty = initialize_empty_topics(topic_amount)\n",
    "\n",
    "topic_list_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###INITIALIZE KEYWORDS FOR EACH TOPIC\n",
    "\n",
    "#State the low and top boarder for key words per topic\n",
    "min_words_per_topic = 4\n",
    "max_words_per_topic = 9\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define a function which will insert the initial keywords for every topic\n",
    "def initialize_keywords_to_topic(empty_topic_list):\n",
    "    for topic in empty_topic_list:\n",
    "        keyword_amount = rnd.randint(min_words_per_topic, max_words_per_topic)\n",
    "        keywords_inserted = 0\n",
    "        while keywords_inserted < keyword_amount:\n",
    "            #Append a unique word to the topic as a keyword of this topic\n",
    "            topic.insert(0,unique_words[keywords_inserted])\n",
    "            #Delete the word out of the baggs of words to ensure, this entry won't be taken a second time\n",
    "            del unique_words[keywords_inserted]\n",
    "            keywords_inserted = keywords_inserted +1\n",
    "    return (empty_topic_list)\n",
    "\n",
    "topic_list = initialize_keywords_to_topic(topic_list_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['half', 'drive', 'hospital', 'training', 'under', 'fish'],\n",
       " ['offer', 'quickly', 'pass', 'three', 'my', 'surface'],\n",
       " ['staff', 'protect', 'summer', 'spring', 'camera'],\n",
       " ['care',\n",
       "  'process',\n",
       "  'reveal',\n",
       "  'pull',\n",
       "  'lay',\n",
       "  'couple',\n",
       "  'not',\n",
       "  'sing',\n",
       "  'everything'],\n",
       " ['window', 'successful', 'about', 'home', 'actually']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###INITIALIZE BEHAVIOURAL PROBABILITIES FOR EACH TOPIC\n",
    "\n",
    "##This function takes an empty topic list and generate for each topic probabilities\n",
    "##Note: The behaviours are implemented as fucntions which are called depending on a random decisionboundry for each \n",
    "##generation step and in this function (initialize_topic_behaviour_parameters) stated probabilities. This \n",
    "##implementation aims to mimic tendencies for behaviours.\n",
    "def initialize_topic_behaviour_parameters(empty_topic_list):\n",
    "\n",
    "    for topic in empty_topic_list:\n",
    "        \n",
    "        \n",
    "        #Initialize the behavioural parameters**\n",
    "        topic_probability_is_elaborated = [float(np.random.uniform(0,1,1)), [0], []]\n",
    "        \n",
    "        topic_probability_creates_new_word = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        topic_probability_uses_different_topic = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        #topic_probability_is_used = [float(np.random.uniform(0,0.5,1)), [0], []]\n",
    "        \n",
    "        #Setting the behavioural parameters here just with implemented with standard uniform distributions in a certain range\n",
    "        #between 0 and 1. Refining these functions in future work could include changing behavioural probabilities depending \n",
    "        #on topic size and topic contents.\n",
    "        \n",
    "        \n",
    "        behavioural_paramters = [topic_probability_is_elaborated, topic_probability_creates_new_word,\n",
    "                                 topic_probability_uses_different_topic] #topic_probability_is_used,]\n",
    "        #,topic_probability_creates_new_word, topic_probability_uses_different_topic\n",
    "        \n",
    "\n",
    "        ##FUTURE WORK: Disruptive Technologien implementieren: Ein Topic einstampfen, wenn ein anderes Steigt.\n",
    "        ##FUTRE WORK: Ressourcen pro Generation implementieren, so wie es wörter für topic gibt, kann es\n",
    "        ##Topics für neue Generation geben. --> Es wird festgelegt wie viele Topics pro Generation generiert werden\n",
    "        ##können / sollen und dann wird die Anzahl gemäß den Wahrscheinlichkeiten als Anteil zugewiesen.\n",
    "\n",
    "        topic.append(behavioural_paramters)\n",
    "        \n",
    "\n",
    "        #IMPORTNANT NOTE:\n",
    "        #BEHAVIOUR 1 = IF TOPIC IS ELABORATED\n",
    "        #BEHAVIOUR 2 = TOPIC CREATES NEW WORD\n",
    "        #BEHAVIOUR 3 = TOPIC USES DIFFERENT TOPIC\n",
    "        #BEHAVIOUR 4 = TOPIC IS USED IN DIFFERENT TOPIC\n",
    "\n",
    "initialize_topic_behaviour_parameters(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['half',\n",
       "  'drive',\n",
       "  'hospital',\n",
       "  'training',\n",
       "  'under',\n",
       "  'fish',\n",
       "  [[0.7146223974979924, [0], []],\n",
       "   [0.12754207822178953, [0], []],\n",
       "   [0.34328948112634283, [0], []]]],\n",
       " ['offer',\n",
       "  'quickly',\n",
       "  'pass',\n",
       "  'three',\n",
       "  'my',\n",
       "  'surface',\n",
       "  [[0.5106246475393696, [0], []],\n",
       "   [0.20877920893548313, [0], []],\n",
       "   [0.04152098505391133, [0], []]]],\n",
       " ['staff',\n",
       "  'protect',\n",
       "  'summer',\n",
       "  'spring',\n",
       "  'camera',\n",
       "  [[0.7089781077513639, [0], []],\n",
       "   [0.21088307586907823, [0], []],\n",
       "   [0.2857114440051213, [0], []]]],\n",
       " ['care',\n",
       "  'process',\n",
       "  'reveal',\n",
       "  'pull',\n",
       "  'lay',\n",
       "  'couple',\n",
       "  'not',\n",
       "  'sing',\n",
       "  'everything',\n",
       "  [[0.9486564086775735, [0], []],\n",
       "   [0.4600346577604153, [0], []],\n",
       "   [0.07419001734046232, [0], []]]],\n",
       " ['window',\n",
       "  'successful',\n",
       "  'about',\n",
       "  'home',\n",
       "  'actually',\n",
       "  [[0.9980750819899569, [0], []],\n",
       "   [0.05434313853137557, [0], []],\n",
       "   [0.35288869819675844, [0], []]]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENSFUNKTIONEN\n",
    "\n",
    "#merge_topic_with_unique_word takes a word (from a topic) and merges it with a random word from unique_words.\n",
    "def merge_topicword_with_uniqueword(word):\n",
    "    word_position = rnd.randint(0,len(unique_words)-1)\n",
    "    new_word = str(word) + str(unique_words[word_position])\n",
    "    \n",
    "    #if the word becomes to long keep the last 12 digits\n",
    "    if len(new_word)>18:\n",
    "        new_word = new_word[:15]\n",
    "    return new_word\n",
    "\n",
    "def use_different_topic(topic_list):\n",
    "    # This implementation enables the error of elaborating on the own topic when choosing a random other topic.\n",
    "    \n",
    "    random_topic_number = rnd.randint(0,len(topic_list)-1)\n",
    "    if random_topic_number < 0:\n",
    "        random_topic_number = 0\n",
    "    \n",
    "    word_position_in_topic = rnd.randint(0,len(topic_list[random_topic_number])-2)\n",
    "    if word_position_in_topic < 0:\n",
    "        word_position_in_topic = 0\n",
    "    \n",
    "    new_word = topic_list[random_topic_number][word_position_in_topic]\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ZÄHLFUNKTIONEN\n",
    "\n",
    "#This function will iterate over the new topic generation and check the behavioural appereance list to set counter\n",
    "def simple_count_function_1(topic_list):\n",
    "    if boolean == True:\n",
    "        print(\"wait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VERHALTENVERÄNDERUNGSFUNKTIONEN\n",
    "\n",
    "def simple_behaviour_change(topic):\n",
    "    \n",
    "    temporary_topic = cp.deepcopy(topic)\n",
    "    \n",
    "    for behaviour in temporary_topic[-1]:\n",
    "        \n",
    "        behaviour[0] = uniform_variance(behaviour[0],0.4)\n",
    "\n",
    "        if behaviour[0] > 1:\n",
    "            behaviour[0] = 0.98\n",
    "    \n",
    "    return temporary_topic\n",
    "\n",
    "#A more complex version could be embedded with:\n",
    "#def simple_behaviour_change(topic):\n",
    "#    while True:\n",
    "#        topic[index of one behaviour]: do something\n",
    "#        topic[index of one behaviour]: do something\n",
    "#        ...        \n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE SUBTOPIC SPACE\n",
    "\n",
    "#this function takes a topic and elaborates a subtopic space on one topic, including changing behavioural probabilities and\n",
    "#counting if behaviours were triggered.\n",
    "\n",
    "\n",
    "#PROBLEMATIK BEI DER IMPLEMENTIERUNG HIER, DASS EIN TOPIC MEHRMALS AUSGEARBEITET WIRD SO\n",
    "#Elaborate the behaviour to the next generation and store initial 0s into the behaviour appereance lists of booleans\n",
    "#(these 0s can then be replaced with 1s if a behaviour is triggered)\n",
    "#Entscheidung ob ein Topic ausgearbeitet wird ändern zu, dass es Ressourcen pro generation gibt und jedes Topic eine Tendenz so\n",
    "#und so viele Ressourcen zu bekommen, dann lassen sich auch die Triggerfunktionen besser implementieren.\n",
    "\n",
    "\n",
    "def elaborate_topic(topic):\n",
    "    \n",
    "    subtopic_space = cp.deepcopy(topic[-1:])\n",
    "    #This slice appends the previous behaviour parameters to the subtopic space (the : is to keep the same list structure, as \n",
    "    #if the topic words would have also been taken)\n",
    "\n",
    "\n",
    "    subtopic_space = simple_behaviour_change(subtopic_space)\n",
    "\n",
    "    \n",
    "    #Set the amounts of words used in that subtopic**\n",
    "    subtopic_word_amount = rnd.randint(4,6)\n",
    "    subtopic_words_picked = 0\n",
    "    \n",
    "\n",
    "    while subtopic_words_picked < subtopic_word_amount:\n",
    "        \n",
    "        decisionboundry = decide()\n",
    "        \n",
    "        #Maybe create a new word\n",
    "        if subtopic_space[-1][1][0] > decisionboundry: #(REF2)\n",
    "            \n",
    "            new_word = cp.deepcopy(merge_topicword_with_uniqueword(topic[rnd.randint(0,len(topic)-2)]))\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            subtopic_words_picked += 1\n",
    "\n",
    "            subtopic_space[-1][1][-1].pop(0)\n",
    "            subtopic_space[-1][1][-1].insert(0,1) #(REF3)\n",
    "\n",
    "            \n",
    "        #Maybe use a different topic\n",
    "        if subtopic_space[-1][2][0] > decisionboundry: #(REF 4)\n",
    "            t_random_1 = rnd.randint(0,len(topic_list)-1)\n",
    "            new_word = cp.deepcopy(use_different_topic(topic_list))\n",
    "            subtopic_space.insert(0,new_word)\n",
    "            subtopic_words_picked += 1\n",
    "            \n",
    "            subtopic_space[-1][2][-1].pop(0)\n",
    "            subtopic_space[-1][2][-1].insert(0,1) #(REF3)\n",
    "        \n",
    "        \n",
    "        #Fill rest of subtopic with topic words\n",
    "        while subtopic_words_picked < subtopic_word_amount:\n",
    "            position_word_elaborated = rnd.randint(0,len(topic)-2) #(REF1)\n",
    "            subtopic_space.insert(0,topic[position_word_elaborated])\n",
    "            subtopic_words_picked += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        #erase duplicates\n",
    "        len1 = len(subtopic_space)-1\n",
    "\n",
    "        subtopic_space[:-1] = list(dict.fromkeys(subtopic_space[:-1]))\n",
    "\n",
    "        len2 = len(subtopic_space)-1\n",
    "\n",
    "        if len1 > len2:\n",
    "            subtopic_words_picked = subtopic_words_picked - (len1-len2)\n",
    "        \n",
    "        if len(subtopic_space) <= 1:\n",
    "            subtopic_space.insert(0,topic[rnd.randint(len(topic)-2)])\n",
    "            subtopic_space.insert(0,topic[rnd.randint(len(topic)-2)])\n",
    "            \n",
    "    return subtopic_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL WILL ELABORATE A TOPIC_SPACE INTO A NEW GENERATION BY USING THE elaborate_topic FUNCTION.\n",
    "\n",
    "\n",
    "\n",
    "def elaborate_topic_space(topic_generation):\n",
    "    \n",
    "        \n",
    "    temporary_generation = cp.deepcopy(topic_generation)\n",
    "    \n",
    "    temp_gen = []\n",
    "\n",
    "    #For createing a new generation, give 0s as in the behaviour appearence list for every behaviour on every topic for this generation\n",
    "    for topic in temporary_generation:\n",
    "        for behaviour in topic[-1]:\n",
    "            behaviour[-1].insert(0,0)\n",
    "    \n",
    "\n",
    "    for topic in temporary_generation:\n",
    "\n",
    "        new_subtopic_space = []\n",
    "        \n",
    "        topic_counter = 0\n",
    "        max_amount_subtopics = 2\n",
    "        \n",
    "        #This loop elaborates a topic dpeending on its probability to be elaborated until the decision_boundry will be\n",
    "        #above the topic probability for being elaborated\n",
    "        while topic_counter < max_amount_subtopics: \n",
    "\n",
    "            \n",
    "            decision_boundry = decide()\n",
    "        \n",
    "            #to test the triggerfunction hypothesis this boundry could be set to a pure random decision (random > random?)\n",
    "            #to ensure, if no triggerfunction is hit, the evolution will be complete random. +\n",
    "            \n",
    "            \n",
    "            # DURCH RANDOM VS RANDOM VERTAUSCHEN FÜR KOMPLETTE ZUFÄLLIGKEIT UM TRIGGERFUNKTIONEN NACHWEISEN ZU KÖNNEN  \n",
    "            if topic[-1][0][0]> decision_boundry+0.1:\n",
    "      \n",
    "\n",
    "                #Call the elaborate_topic_function which returns a subtopic space for the topic including new elements and \n",
    "                temp_gen.insert(0,elaborate_topic(topic)) #elaborate topic uses cp.deepcopy(topic) to generate a clone not a clone of the object pointer\n",
    "                \n",
    "                topic_counter += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    \n",
    "    \n",
    "    new_generation = [element for element in temp_gen if element != []]\n",
    "    \n",
    "    #if len(new_generation) > 2000:\n",
    "    #    max_amount_subtopics = 1\n",
    "\n",
    "    \n",
    "    \n",
    "    return(new_generation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = []\n",
    "\n",
    "def start_generator(initial_topic_list):\n",
    "    \n",
    "    master.insert(0,initial_topic_list)\n",
    "    \n",
    "    #Initialize the new_topic_generation which is handed to the elaborate_topic_list function\n",
    "    next_topic_generation = elaborate_topic_space(initial_topic_list)\n",
    "    \n",
    "    master.insert(0,next_topic_generation)\n",
    "\n",
    "    #State the amount of generations\n",
    "    amount_of_generations = 50\n",
    "    generations_created = 0\n",
    "    \n",
    "    while generations_created < amount_of_generations:\n",
    "        print(\"Generation number: \", generations_created, \" in progress\")\n",
    "        next_topic_generation = elaborate_topic_space(next_topic_generation)\n",
    "        \n",
    "        next_topic_generation = trigger_functions(next_topic_generation)\n",
    "        \n",
    "        master.insert(0,cp.deepcopy(next_topic_generation))     \n",
    "        \n",
    "        generations_created = generations_created + 1\n",
    "        \n",
    "        cleaned_master = [element for element in master if element != []]\n",
    "        \n",
    "    return cleaned_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_functions(topic_generation):\n",
    "    \n",
    "    #for building the trigger function multiple approaches are possible. For this prototype a simple approach with asking\n",
    "    #of a certain order of behaviour appereances of two distinguish topics are given.\n",
    "    new_gen = cp.deepcopy(topic_generation)\n",
    "    \n",
    "    generation_counter = 0\n",
    "    generation_len = len(new_gen)-1\n",
    "    \n",
    "    first_hit = -1\n",
    "    second_hit = -1\n",
    "    \n",
    "    for topic in new_gen:\n",
    "        generation_counter += 1\n",
    "        if [1,0,1,0,1,0] in topic[-1][1][-1][:6]:\n",
    "            #print(\"UUUUNOOO\", generation_counter)\n",
    "            first_hit = generation_counter\n",
    "        if [1,1,1,0] in topic[-1][2][-1][:5]:\n",
    "            #print(\"DOOOOS\", generation_counter)\n",
    "            second_hit = generation_counter\n",
    "    \n",
    "    if first_hit != -1 and second_hit != -1:\n",
    "        new_gen[first_hit][-1][1][0] = 5\n",
    "        new_gen[second_hit][-1][2][0] = 5\n",
    "        print(\"Trigger hit in generation:\", generation_counter)\n",
    "    \n",
    "    return new_gen\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation number:  0  in progress\n",
      "Generation number:  1  in progress\n",
      "Generation number:  2  in progress\n",
      "Generation number:  3  in progress\n",
      "Generation number:  4  in progress\n",
      "Generation number:  5  in progress\n",
      "Generation number:  6  in progress\n",
      "Generation number:  7  in progress\n",
      "Generation number:  8  in progress\n",
      "Generation number:  9  in progress\n",
      "Generation number:  10  in progress\n",
      "Generation number:  11  in progress\n",
      "Generation number:  12  in progress\n",
      "Generation number:  13  in progress\n",
      "Generation number:  14  in progress\n",
      "Generation number:  15  in progress\n",
      "Generation number:  16  in progress\n",
      "Generation number:  17  in progress\n",
      "Generation number:  18  in progress\n",
      "Generation number:  19  in progress\n",
      "Generation number:  20  in progress\n",
      "Generation number:  21  in progress\n",
      "Generation number:  22  in progress\n",
      "Generation number:  23  in progress\n",
      "Generation number:  24  in progress\n",
      "Generation number:  25  in progress\n",
      "Generation number:  26  in progress\n",
      "Generation number:  27  in progress\n",
      "Generation number:  28  in progress\n",
      "Generation number:  29  in progress\n",
      "Generation number:  30  in progress\n",
      "Generation number:  31  in progress\n",
      "Generation number:  32  in progress\n",
      "Generation number:  33  in progress\n",
      "Generation number:  34  in progress\n",
      "Generation number:  35  in progress\n",
      "Generation number:  36  in progress\n",
      "Generation number:  37  in progress\n",
      "Generation number:  38  in progress\n",
      "Generation number:  39  in progress\n",
      "Generation number:  40  in progress\n",
      "Generation number:  41  in progress\n",
      "Generation number:  42  in progress\n",
      "Generation number:  43  in progress\n",
      "Generation number:  44  in progress\n",
      "Generation number:  45  in progress\n",
      "Generation number:  46  in progress\n",
      "Generation number:  47  in progress\n",
      "Generation number:  48  in progress\n",
      "Generation number:  49  in progress\n"
     ]
    }
   ],
   "source": [
    "final = start_generator(topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breiten Wachstumsbegrenzung durch:  (1) max_amount_subtopics = 2 und (2) die Entscheidungsgrenze, ob ein Topic ausgearbeitet wird wird um 0.1 erhöt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135408\n",
      "109321\n",
      "87801\n",
      "71038\n",
      "57593\n",
      "46684\n",
      "37672\n",
      "30362\n",
      "24467\n",
      "19533\n",
      "15706\n",
      "12691\n",
      "10237\n",
      "8301\n",
      "6637\n",
      "5385\n",
      "4352\n",
      "3555\n",
      "2840\n",
      "2314\n",
      "1865\n",
      "1512\n",
      "1202\n",
      "963\n",
      "771\n",
      "622\n",
      "514\n",
      "413\n",
      "324\n",
      "274\n",
      "213\n",
      "182\n",
      "148\n",
      "131\n",
      "121\n",
      "94\n",
      "73\n",
      "65\n",
      "48\n",
      "38\n",
      "26\n",
      "20\n",
      "17\n",
      "11\n",
      "11\n",
      "10\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for generation in final:\n",
    "    print(len(generation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Triggerfunktion wurde nicht aktiviert."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
